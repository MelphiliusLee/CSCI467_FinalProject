{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.tree import plot_tree\n",
    "import seaborn as sns\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute the average stats for each team\n",
    "def compute_team_average_stats(game_data_path, team_details_path, output_path):\n",
    "    df = pd.read_csv(game_data_path)\n",
    "    teams_df = pd.read_csv(team_details_path)\n",
    "\n",
    "    features_home = ['fg3_pct_home', 'ft_pct_home', 'oreb_home', 'dreb_home', 'reb_home', 'ast_home', 'stl_home',\n",
    "                     'blk_home', 'tov_home', 'wl_home']\n",
    "    features_away = ['fg3_pct_away', 'ft_pct_away', 'oreb_away', 'dreb_away', 'reb_away', 'ast_away', 'stl_away',\n",
    "                     'blk_away', 'tov_away', 'wl_away']\n",
    "\n",
    "    home_stats = df[['team_id_home'] + features_home]\n",
    "    away_stats = df[['team_id_away'] + features_away]\n",
    "\n",
    "    home_stats.columns = ['team_id'] + \\\n",
    "        [col.replace('_home', '') for col in features_home]\n",
    "    away_stats.columns = ['team_id'] + \\\n",
    "        [col.replace('_away', '') for col in features_away]\n",
    "\n",
    "    combined_stats = pd.concat([home_stats, away_stats], ignore_index=True)\n",
    "    average_stats = combined_stats.groupby(\n",
    "        'team_id').agg(lambda x: x.mean()).reset_index()\n",
    "    average_stats.columns = [\n",
    "        col if col != 'team_id' else col for col in average_stats.columns]\n",
    "\n",
    "    average_stats = pd.merge(\n",
    "        average_stats, teams_df[['team_id', 'abbreviation']], on='team_id')\n",
    "\n",
    "    average_stats.to_csv(output_path, index=False)\n",
    "    print(f\"Team average stats saved to {output_path}\")\n",
    "\n",
    "# merge the game data with the team average stats to avoid overfitting\n",
    "def augment_game_data_with_team_stats(game_data_path, team_stats_path):\n",
    "    df_games = pd.read_csv(game_data_path)\n",
    "    df_team_avg = pd.read_csv(team_stats_path)\n",
    "    home_columns = {\n",
    "        col: col + \"_home_avg\" for col in df_team_avg.columns if col not in [\"team_id\", \"abbreviation\"]}\n",
    "    away_columns = {\n",
    "        col: col + \"_away_avg\" for col in df_team_avg.columns if col not in [\"team_id\", \"abbreviation\"]}\n",
    "\n",
    "    df_team_avg_home = df_team_avg.rename(columns=home_columns)\n",
    "    df_team_avg_away = df_team_avg.rename(columns=away_columns)\n",
    "\n",
    "    df_merged = pd.merge(df_games, df_team_avg_home, how=\"left\",\n",
    "                         left_on=\"team_id_home\", right_on=\"team_id\")\n",
    "    df_merged = pd.merge(df_merged, df_team_avg_away,\n",
    "                         how=\"left\", left_on=\"team_id_away\", right_on=\"team_id\")\n",
    "    df = df_merged.dropna(axis=0)\n",
    "\n",
    "    df.to_csv('data/merged_data_complete.csv', index=False)\n",
    "    # print(df)\n",
    "    return df\n",
    "\n",
    "# the logistic regression model\n",
    "# def logistic_regression_model(X_train, y_train, X_dev, y_dev description, printing, plot=False):\n",
    "#     model = LogisticRegression(max_iter=1000)\n",
    "#     model.fit(x_train, y_train)\n",
    "\n",
    "#     y_pred = model.predict(x_test)\n",
    "#     accuracy = accuracy_score(y_test, y_pred)\n",
    "#     print(f'{description} Logistic Regression Model Accuracy: {accuracy:.2f}')\n",
    "#     # cm = confusion_matrix(y_test, y_pred)\n",
    "#     # print(\"Confusion Matrix:\")\n",
    "#     # print(cm)\n",
    "#     coefficients = model.coef_[0]\n",
    "#     feature_names = x.columns.tolist()\n",
    "\n",
    "#     sorted_indices = sorted(range(len(coefficients)),\n",
    "#                             key=lambda i: abs(coefficients[i]), reverse=True)\n",
    "#     sorted_coefficients = [coefficients[i] for i in sorted_indices]\n",
    "#     sorted_feature_names = [feature_names[i] for i in sorted_indices]\n",
    "#     if printing == 1:\n",
    "#         print(\"WEIGHTS:\")\n",
    "#         for coefficient, feature_name in zip(sorted_coefficients, sorted_feature_names):\n",
    "#             print(f\"{feature_name}: {coefficient}\")\n",
    "#     if plot:\n",
    "#         matplotlib.use('TkAgg')\n",
    "\n",
    "#         coef_df = pd.DataFrame(\n",
    "#             {'Feature': sorted_feature_names, 'Coefficient': sorted_coefficients})\n",
    "#         plt.figure(figsize=(10, 8))\n",
    "#         sns.barplot(x=\"Coefficient\", y=\"Feature\", data=coef_df)\n",
    "#         plt.title('Feature Importances in Logistic Regression')\n",
    "#         plt.xlabel('Coefficient Value')\n",
    "#         plt.ylabel('Features')\n",
    "#         plt.show()\n",
    "\n",
    "#     return model\n",
    "\n",
    "# # the support vector machine model\n",
    "# def svm_model(X, y, description, printing):\n",
    "#     x_train, x_test, y_train, y_test = train_test_split(\n",
    "#         X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "#     # Linear kernel for simplicity, can try other kernels\n",
    "#     model = SVC(kernel='linear', random_state=42)\n",
    "#     model.fit(x_train, y_train)\n",
    "\n",
    "#     accuracy = model.score(x_test, y_test)\n",
    "#     print(f'{description} SVM Model Accuracy: {accuracy:.2f}')\n",
    "\n",
    "#     if printing == 1:\n",
    "#         print(\"SVM Parameters:\")\n",
    "#         print(model.get_params())\n",
    "\n",
    "#     return model\n",
    "\n",
    "# # the neural network model\n",
    "# def neural_network_model(x, y, description):\n",
    "#     x_train, x_test, y_train, y_test = train_test_split(\n",
    "#         x, y, test_size=0.3, random_state=42)\n",
    "\n",
    "#     model = MLPClassifier(hidden_layer_sizes=(\n",
    "#         100, 50), max_iter=500, activation='relu', solver='adam', random_state=42)\n",
    "#     model.fit(x_train, y_train)\n",
    "\n",
    "#     accuracy = model.score(x_test, y_test)\n",
    "#     print(f'{description} Neural Network Model Accuracy: {accuracy:.2f}')\n",
    "\n",
    "#     return model\n",
    "\n",
    "# # the decision tree model\n",
    "# def train_and_visualize_decision_tree(data_path, features, target, test_size=0.3, random_state=42, max_depth=5):\n",
    "#     matplotlib.use('TkAgg')\n",
    "#     df = pd.read_csv(data_path)\n",
    "\n",
    "#     X = df[features]\n",
    "#     y = df[target]\n",
    "\n",
    "#     X_train, X_test, y_train, y_test = train_test_split(\n",
    "#         X, y, test_size=test_size, random_state=random_state)\n",
    "\n",
    "#     tree = DecisionTreeClassifier(\n",
    "#         max_depth=max_depth, random_state=random_state)\n",
    "#     tree.fit(X_train, y_train)\n",
    "\n",
    "#     y_pred = tree.predict(X_test)\n",
    "#     accuracy = accuracy_score(y_test, y_pred)\n",
    "#     print(f'Accuracy: {accuracy:.2f}')\n",
    "\n",
    "#     plt.figure(figsize=(20, 10))\n",
    "#     plot_tree(tree, filled=True, feature_names=features,\n",
    "#               class_names=['Loss', 'Win'], rounded=True, fontsize=12)\n",
    "#     plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Team average stats saved to data/team_average_stats_combined.csv\n"
     ]
    }
   ],
   "source": [
    "# Data Preprocessing\n",
    "game_data_path = 'data/game_data.csv' # path to the game data\n",
    "team_details_path = 'data/team_details.csv' # path to the team details\n",
    "combined_stats_path = 'data/team_average_stats_combined.csv' # path to the combined average stats\n",
    "\n",
    "# convert the game data to the merged data\n",
    "compute_team_average_stats(game_data_path, team_details_path, combined_stats_path)\n",
    "df_augmented = augment_game_data_with_team_stats(game_data_path, combined_stats_path)\n",
    "\n",
    "features_prefined = ['fg3_pct_home_avg', 'ft_pct_home_avg', 'oreb_home_avg', 'dreb_home_avg', 'ast_home_avg',\n",
    "                         'reb_home_avg', 'stl_home_avg', 'blk_home_avg', 'tov_home_avg', 'fg3_pct_away_avg', 'ft_pct_away_avg', 'oreb_away_avg', 'dreb_away_avg', 'ast_away_avg',\n",
    "                         'reb_away_avg', 'stl_away_avg', 'blk_away_avg', 'tov_away_avg']\n",
    "features_baseline = ['fg3_pct_home_avg', 'fg3_pct_away_avg']\n",
    "\n",
    "# split the data into features and target, \n",
    "X_prefined = df_augmented[features_prefined]\n",
    "X_baseline = df_augmented[features_baseline]\n",
    "y = df_augmented['wl_home']\n",
    "\n",
    "# split the data into training, development, and testing\n",
    "X_train_prefined, X_test_prefined, y_train, y_test = train_test_split(X_prefined, y, test_size=0.3, random_state=42)\n",
    "X_train_baseline, X_test_baseline = train_test_split(X_baseline, test_size=0.3, random_state=42)\n",
    "X_dev_prefined, X_test_prefined, y_dev, y_test = train_test_split(X_test_prefined, y_test, test_size=0.5, random_state=42)\n",
    "X_dev_baseline, X_test_baseline = train_test_split(X_test_baseline, test_size=0.5, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2488, 2)\n",
      "(533, 2)\n",
      "(534, 2)\n",
      "      fg3_pct_home_avg  fg3_pct_away_avg\n",
      "1328          0.365899          0.368306\n",
      "3555          0.354074          0.371405\n",
      "2153          0.354074          0.348697\n",
      "819           0.346322          0.362968\n",
      "3410          0.368306          0.380565\n",
      "      fg3_pct_home_avg  ft_pct_home_avg  oreb_home_avg  dreb_home_avg  \\\n",
      "233           0.356782         0.807259      10.357558      33.901163   \n",
      "3184          0.339892         0.749864      10.487952      33.376506   \n",
      "475           0.365899         0.782590      10.111702      33.688830   \n",
      "2963          0.358616         0.791506       9.286164      33.949686   \n",
      "2162          0.364152         0.783493       9.724928      34.621777   \n",
      "\n",
      "      ast_home_avg  reb_home_avg  stl_home_avg  blk_home_avg  tov_home_avg  \\\n",
      "233      24.130814     44.258721      7.206395      4.651163     13.485465   \n",
      "3184     22.750000     43.864458      7.798193      4.795181     15.590361   \n",
      "475      27.095745     43.800532      7.545213      4.324468     14.026596   \n",
      "2963     24.676101     43.235849      7.896226      4.273585     14.194969   \n",
      "2162     27.618911     44.346705      8.117479      4.495702     15.275072   \n",
      "\n",
      "      fg3_pct_away_avg  ft_pct_away_avg  oreb_away_avg  dreb_away_avg  \\\n",
      "233           0.354074         0.784657      11.275148      32.633136   \n",
      "3184          0.354074         0.784657      11.275148      32.633136   \n",
      "475           0.348697         0.756173      12.000000      35.198847   \n",
      "2963          0.346322         0.764790      10.391720      32.181529   \n",
      "2162          0.368306         0.779723      10.527697      35.568513   \n",
      "\n",
      "      ast_away_avg  reb_away_avg  stl_away_avg  blk_away_avg  tov_away_avg  \n",
      "233      23.721893     43.908284      8.976331      5.053254     13.085799  \n",
      "3184     23.721893     43.908284      8.976331      5.053254     13.085799  \n",
      "475      26.207493     47.198847      8.827089      5.703170     13.956772  \n",
      "2963     23.560510     42.573248      7.378981      4.547771     15.015924  \n",
      "2162     23.373178     46.096210      6.463557      4.760933     14.600583  \n"
     ]
    }
   ],
   "source": [
    "print(X_train_baseline.shape)\n",
    "print(X_dev_baseline.shape)\n",
    "print(X_test_baseline.shape)\n",
    "print(X_dev_baseline.head())\n",
    "print(X_test_prefined.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Accuracy: 0.5928705440900562 when l1 = 0.1, max_iter = 100, solver = saga\n",
      "Prefined Accuracy: 0.6097560975609756 when l1 = 0.1, max_iter = 100, solver = saga\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Accuracy: 0.5928705440900562 when l1 = 0.1, max_iter = 500, solver = saga\n",
      "Prefined Accuracy: 0.6210131332082551 when l1 = 0.1, max_iter = 500, solver = saga\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Accuracy: 0.5928705440900562 when l1 = 0.1, max_iter = 1000, solver = saga\n",
      "Prefined Accuracy: 0.6210131332082551 when l1 = 0.1, max_iter = 1000, solver = saga\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Accuracy: 0.5928705440900562 when l1 = 0.1, max_iter = 2000, solver = saga\n",
      "Prefined Accuracy: 0.6210131332082551 when l1 = 0.1, max_iter = 2000, solver = saga\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Accuracy: 0.5928705440900562 when l1 = 0.1, max_iter = 5000, solver = saga\n",
      "Prefined Accuracy: 0.6210131332082551 when l1 = 0.1, max_iter = 5000, solver = saga\n",
      "Baseline Accuracy: 0.5928705440900562 when l1 = 0.5, max_iter = 100, solver = saga\n",
      "Prefined Accuracy: 0.6097560975609756 when l1 = 0.5, max_iter = 100, solver = saga\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Accuracy: 0.5928705440900562 when l1 = 0.5, max_iter = 500, solver = saga\n",
      "Prefined Accuracy: 0.6191369606003753 when l1 = 0.5, max_iter = 500, solver = saga\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Accuracy: 0.5928705440900562 when l1 = 0.5, max_iter = 1000, solver = saga\n",
      "Prefined Accuracy: 0.6191369606003753 when l1 = 0.5, max_iter = 1000, solver = saga\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Accuracy: 0.5928705440900562 when l1 = 0.5, max_iter = 2000, solver = saga\n",
      "Prefined Accuracy: 0.6191369606003753 when l1 = 0.5, max_iter = 2000, solver = saga\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Accuracy: 0.5928705440900562 when l1 = 0.5, max_iter = 5000, solver = saga\n",
      "Prefined Accuracy: 0.6191369606003753 when l1 = 0.5, max_iter = 5000, solver = saga\n",
      "Baseline Accuracy: 0.5928705440900562 when l1 = 0.9, max_iter = 100, solver = saga\n",
      "Prefined Accuracy: 0.6097560975609756 when l1 = 0.9, max_iter = 100, solver = saga\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Accuracy: 0.5928705440900562 when l1 = 0.9, max_iter = 500, solver = saga\n",
      "Prefined Accuracy: 0.6191369606003753 when l1 = 0.9, max_iter = 500, solver = saga\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Accuracy: 0.5928705440900562 when l1 = 0.9, max_iter = 1000, solver = saga\n",
      "Prefined Accuracy: 0.6191369606003753 when l1 = 0.9, max_iter = 1000, solver = saga\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Accuracy: 0.5928705440900562 when l1 = 0.9, max_iter = 2000, solver = saga\n",
      "Prefined Accuracy: 0.6191369606003753 when l1 = 0.9, max_iter = 2000, solver = saga\n",
      "Baseline Accuracy: 0.5928705440900562 when l1 = 0.9, max_iter = 5000, solver = saga\n",
      "Prefined Accuracy: 0.6191369606003753 when l1 = 0.9, max_iter = 5000, solver = saga\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# train the logistic regression model\n",
    "# hyperparameters to tune: max_iter, solver, penalty, l1_ratio\n",
    "penalties = 'elasticnet'\n",
    "l1_ratios = [0.1, 0.5, 0.9]\n",
    "max_iters = [100, 500, 1000, 2000, 5000]\n",
    "solver = 'saga'\n",
    "\n",
    "best_baseline_accuracy = np.zeros(1)\n",
    "best_prefined_accuracy = np.zeros(1)\n",
    "\n",
    "best_baseline_model = None\n",
    "best_prefined_model = None\n",
    "\n",
    "best_baseline_settings = {\n",
    "    \"penalty\": 'elasticnet',\n",
    "    \"l1_ratio\": None,\n",
    "    \"max_iter\": None,\n",
    "    \"solver\": 'saga'\n",
    "}\n",
    "best_prefined_settings = {\n",
    "    \"penalty\": 'elasticnet',\n",
    "    \"l1_ratio\": None,\n",
    "    \"max_iter\": None,\n",
    "    \"solver\": 'saga'\n",
    "}\n",
    "# Loop through parameters\n",
    "for l1 in l1_ratios:\n",
    "    for m in max_iters:\n",
    "        # ===== Implement a network with iterated settings ===== #\n",
    "        # Note: set validation_fraction to 0.1 or leave as default\n",
    "        log_reg_baseline = LogisticRegression(penalty=penalties, l1_ratio=l1, max_iter=m, solver=solver)\n",
    "        log_reg_prefined = LogisticRegression(penalty=penalties, l1_ratio=l1, max_iter=m, solver=solver)\n",
    "        # ===== End of Implement a network with iterated settings ===== #\n",
    "\n",
    "        # ===== Train network ===== #\n",
    "        log_reg_baseline.fit(X_train_baseline, y_train)\n",
    "        log_reg_prefined.fit(X_train_prefined, y_train)\n",
    "        # ===== End of Train network ===== #\n",
    "\n",
    "        # ===== Test network ===== #\n",
    "        # train accuracy\n",
    "        train_accuracy_baseline = log_reg_baseline.score(X_train_baseline, y_train)\n",
    "        train_accuracy_prefined = log_reg_prefined.score(X_train_prefined, y_train)\n",
    "        \n",
    "        # inference\n",
    "        baseline_pred = log_reg_baseline.predict(X_dev_baseline)\n",
    "        prefined_pred = log_reg_prefined.predict(X_dev_prefined)\n",
    "        \n",
    "        # Compute accuracy\n",
    "        baseline_accuracy = accuracy_score(y_dev, baseline_pred)\n",
    "        print(f\"Baseline Accuracy: {baseline_accuracy} when l1 = {l1}, max_iter = {m}, solver = {solver}\")\n",
    "        prefined_accuracy = accuracy_score(y_dev, prefined_pred)\n",
    "        print(f\"Prefined Accuracy: {prefined_accuracy} when l1 = {l1}, max_iter = {m}, solver = {solver}\")\n",
    "        \n",
    "        # Compute precision\n",
    "        baseline_precision = precision_score(y_dev, baseline_pred)\n",
    "        prefined_precision = precision_score(y_dev, prefined_pred)\n",
    "        \n",
    "        # Compute recall\n",
    "        baseline_recall = recall_score(y_dev, baseline_pred)\n",
    "        prefined_recall = recall_score(y_dev, prefined_pred)\n",
    "        \n",
    "        # Compute f1 score\n",
    "        baseline_f1 = f1_score(y_dev, baseline_pred)\n",
    "        prefined_f1 = f1_score(y_dev, prefined_pred)\n",
    "        # ===== End of Test network ===== #\n",
    "\n",
    "        # ===== Is it the best setting ===== #\n",
    "        if baseline_accuracy >= best_baseline_accuracy:\n",
    "            best_baseline_accuracy = baseline_accuracy\n",
    "            best_baseline_settings = {\n",
    "                \"penalty\": penalties,\n",
    "                \"l1_ratio\": l1,\n",
    "                \"max_iter\": m,\n",
    "                \"solver\": solver\n",
    "            }\n",
    "            best_baseline_model = log_reg_baseline\n",
    "            \n",
    "        if prefined_accuracy >= best_prefined_accuracy:\n",
    "            best_prefined_accuracy = prefined_accuracy\n",
    "            best_prefined_settings = {\n",
    "                \"penalty\": penalties,\n",
    "                \"l1_ratio\": l1,\n",
    "                \"max_iter\": m,\n",
    "                \"solver\": solver\n",
    "            }\n",
    "            best_prefined_model = log_reg_prefined\n",
    "        # ===== End of Is it the best setting ===== #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best baseline settings:  {'penalty': 'elasticnet', 'l1_ratio': 0.9, 'max_iter': 5000, 'solver': 'saga'}\n",
      "Best prefined settings:  {'penalty': 'elasticnet', 'l1_ratio': 0.1, 'max_iter': 5000, 'solver': 'saga'}\n",
      "Best baseline accuracy:  0.5928705440900562\n",
      "Best prefined accuracy:  0.6210131332082551\n"
     ]
    }
   ],
   "source": [
    "print (\"Best baseline settings: \", best_baseline_settings)\n",
    "print (\"Best prefined settings: \", best_prefined_settings)\n",
    "print (\"Best baseline accuracy: \", best_baseline_accuracy)\n",
    "print (\"Best prefined accuracy: \", best_prefined_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Accuracy on test set: 0.5674157303370787\n",
      "Prefined Accuracy on test set: 0.5898876404494382\n",
      "Baseline Precision on test set: 0.5674157303370787\n",
      "Prefined Precision on test set: 0.6099476439790575\n",
      "Baseline Recall on test set: 1.0\n",
      "Prefined Recall on test set: 0.768976897689769\n",
      "Baseline F1 on test set: 0.7240143369175627\n",
      "Prefined F1 on test set: 0.6802919708029197\n"
     ]
    }
   ],
   "source": [
    "# run on test set\n",
    "baseline_pred = best_baseline_model.predict(X_test_baseline)\n",
    "prefined_pred = best_prefined_model.predict(X_test_prefined)\n",
    "\n",
    "baseline_accuracy = accuracy_score(y_test, baseline_pred)\n",
    "prefined_accuracy = accuracy_score(y_test, prefined_pred)\n",
    "\n",
    "print(f\"Baseline Accuracy on test set: {baseline_accuracy}\")\n",
    "print(f\"Prefined Accuracy on test set: {prefined_accuracy}\")\n",
    "\n",
    "baseline_precision = precision_score(y_test, baseline_pred)\n",
    "prefined_precision = precision_score(y_test, prefined_pred)\n",
    "\n",
    "baseline_recall = recall_score(y_test, baseline_pred)\n",
    "prefined_recall = recall_score(y_test, prefined_pred)\n",
    "\n",
    "baseline_f1 = f1_score(y_test, baseline_pred)\n",
    "prefined_f1 = f1_score(y_test, prefined_pred)\n",
    "\n",
    "print(f\"Baseline Precision on test set: {baseline_precision}\")\n",
    "print(f\"Prefined Precision on test set: {prefined_precision}\")\n",
    "print(f\"Baseline Recall on test set: {baseline_recall}\")\n",
    "print(f\"Prefined Recall on test set: {prefined_recall}\")\n",
    "print(f\"Baseline F1 on test set: {baseline_f1}\")\n",
    "print(f\"Prefined F1 on test set: {prefined_f1}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Accuracy: 0.5928705440900562 when C = 0.1, kernel = linear, shrinking = True\n",
      "Prefined Accuracy: 0.6097560975609756 when C = 0.1, kernel = linear, shrinking = True\n",
      "Baseline Accuracy: 0.5928705440900562 when C = 0.1, kernel = linear, shrinking = False\n",
      "Prefined Accuracy: 0.6097560975609756 when C = 0.1, kernel = linear, shrinking = False\n",
      "Baseline Accuracy: 0.5853658536585366 when C = 0.1, kernel = rbf, shrinking = True\n",
      "Prefined Accuracy: 0.5928705440900562 when C = 0.1, kernel = rbf, shrinking = True\n",
      "Baseline Accuracy: 0.5853658536585366 when C = 0.1, kernel = rbf, shrinking = False\n",
      "Prefined Accuracy: 0.5928705440900562 when C = 0.1, kernel = rbf, shrinking = False\n",
      "Baseline Accuracy: 0.5928705440900562 when C = 0.1, kernel = sigmoid, shrinking = True\n",
      "Prefined Accuracy: 0.5928705440900562 when C = 0.1, kernel = sigmoid, shrinking = True\n",
      "Baseline Accuracy: 0.5928705440900562 when C = 0.1, kernel = sigmoid, shrinking = False\n",
      "Prefined Accuracy: 0.5928705440900562 when C = 0.1, kernel = sigmoid, shrinking = False\n",
      "Baseline Accuracy: 0.5928705440900562 when C = 1, kernel = linear, shrinking = True\n",
      "Prefined Accuracy: 0.6097560975609756 when C = 1, kernel = linear, shrinking = True\n",
      "Baseline Accuracy: 0.5928705440900562 when C = 1, kernel = linear, shrinking = False\n",
      "Prefined Accuracy: 0.6097560975609756 when C = 1, kernel = linear, shrinking = False\n",
      "Baseline Accuracy: 0.5853658536585366 when C = 1, kernel = rbf, shrinking = True\n",
      "Prefined Accuracy: 0.5928705440900562 when C = 1, kernel = rbf, shrinking = True\n",
      "Baseline Accuracy: 0.5853658536585366 when C = 1, kernel = rbf, shrinking = False\n",
      "Prefined Accuracy: 0.5928705440900562 when C = 1, kernel = rbf, shrinking = False\n",
      "Baseline Accuracy: 0.5928705440900562 when C = 1, kernel = sigmoid, shrinking = True\n",
      "Prefined Accuracy: 0.5928705440900562 when C = 1, kernel = sigmoid, shrinking = True\n",
      "Baseline Accuracy: 0.5928705440900562 when C = 1, kernel = sigmoid, shrinking = False\n",
      "Prefined Accuracy: 0.5928705440900562 when C = 1, kernel = sigmoid, shrinking = False\n",
      "Baseline Accuracy: 0.5928705440900562 when C = 10, kernel = linear, shrinking = True\n",
      "Prefined Accuracy: 0.5928705440900562 when C = 10, kernel = linear, shrinking = True\n",
      "Baseline Accuracy: 0.5928705440900562 when C = 10, kernel = linear, shrinking = False\n",
      "Prefined Accuracy: 0.5928705440900562 when C = 10, kernel = linear, shrinking = False\n",
      "Baseline Accuracy: 0.5816135084427767 when C = 10, kernel = rbf, shrinking = True\n",
      "Prefined Accuracy: 0.600375234521576 when C = 10, kernel = rbf, shrinking = True\n",
      "Baseline Accuracy: 0.5816135084427767 when C = 10, kernel = rbf, shrinking = False\n",
      "Prefined Accuracy: 0.600375234521576 when C = 10, kernel = rbf, shrinking = False\n",
      "Baseline Accuracy: 0.5928705440900562 when C = 10, kernel = sigmoid, shrinking = True\n",
      "Prefined Accuracy: 0.5422138836772983 when C = 10, kernel = sigmoid, shrinking = True\n",
      "Baseline Accuracy: 0.5928705440900562 when C = 10, kernel = sigmoid, shrinking = False\n",
      "Prefined Accuracy: 0.5422138836772983 when C = 10, kernel = sigmoid, shrinking = False\n"
     ]
    }
   ],
   "source": [
    "# Train svm model\n",
    "Cs = [0.1, 1, 10]\n",
    "kernels = ['linear', 'rbf', 'sigmoid']\n",
    "shrinking = [True, False]\n",
    "\n",
    "best_baseline_accuracy = np.zeros(1)\n",
    "best_prefined_accuracy = np.zeros(1)\n",
    "\n",
    "best_baseline_svm = None\n",
    "best_prefined_svm = None\n",
    "\n",
    "best_baseline_settings = {\n",
    "    \"C\": None,\n",
    "    \"kernel\": None,\n",
    "    \"shrinking\": None\n",
    "}\n",
    "best_prefined_settings = {\n",
    "    \"C\": None,\n",
    "    \"kernel\": None,\n",
    "    \"shrinking\": None\n",
    "}\n",
    "\n",
    "for c in Cs:\n",
    "    for k in kernels:\n",
    "        for s in shrinking:\n",
    "            svm_baseline = SVC(C=c, kernel=k, shrinking=s)\n",
    "            svm_prefined = SVC(C=c, kernel=k, shrinking=s)\n",
    "            \n",
    "            # Train network\n",
    "            svm_baseline.fit(X_train_baseline, y_train)\n",
    "            svm_prefined.fit(X_train_prefined, y_train)\n",
    "            \n",
    "            # Test network\n",
    "            # train accuracy\n",
    "            train_accuracy_baseline = svm_baseline.score(X_train_baseline, y_train)\n",
    "            train_accuracy_prefined = svm_prefined.score(X_train_prefined, y_train)\n",
    "            \n",
    "            # inference\n",
    "            baseline_pred = svm_baseline.predict(X_dev_baseline)\n",
    "            prefined_pred = svm_prefined.predict(X_dev_prefined)\n",
    "            \n",
    "            # Compute accuracy\n",
    "            baseline_accuracy = accuracy_score(y_dev, baseline_pred)\n",
    "            print(f\"Baseline Accuracy: {baseline_accuracy} when C = {c}, kernel = {k}, shrinking = {s}\")\n",
    "            prefined_accuracy = accuracy_score(y_dev, prefined_pred)\n",
    "            print(f\"Prefined Accuracy: {prefined_accuracy} when C = {c}, kernel = {k}, shrinking = {s}\")\n",
    "            \n",
    "            # Compute precision\n",
    "            baseline_precision = precision_score(y_dev, baseline_pred)\n",
    "            prefined_precision = precision_score(y_dev, prefined_pred)\n",
    "            \n",
    "            # Compute recall\n",
    "            baseline_recall = recall_score(y_dev, baseline_pred)\n",
    "            prefined_recall = recall_score(y_dev, prefined_pred)\n",
    "            \n",
    "            # Compute f1 score\n",
    "            baseline_f1 = f1_score(y_dev, baseline_pred)\n",
    "            prefined_f1 = f1_score(y_dev, prefined_pred)\n",
    "            \n",
    "            # Is it the best setting\n",
    "            if baseline_accuracy >= best_baseline_accuracy:\n",
    "                best_baseline_accuracy = baseline_accuracy\n",
    "                best_baseline_settings = {\n",
    "                    \"C\": c,\n",
    "                    \"kernel\": k,\n",
    "                    \"shrinking\": s\n",
    "                }  \n",
    "                best_baseline_svm = svm_baseline\n",
    "            if prefined_accuracy >= best_prefined_accuracy:\n",
    "                best_prefined_accuracy = prefined_accuracy\n",
    "                best_prefined_settings = {\n",
    "                    \"C\": c,\n",
    "                    \"kernel\": k,\n",
    "                    \"shrinking\": s\n",
    "                }\n",
    "                best_prefined_svm = svm_prefined\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best baseline settings:  {'C': 10, 'kernel': 'sigmoid', 'shrinking': False}\n",
      "Best prefined settings:  {'C': 1, 'kernel': 'linear', 'shrinking': False}\n",
      "Best baseline accuracy:  0.5928705440900562\n",
      "Best prefined accuracy:  0.6097560975609756\n"
     ]
    }
   ],
   "source": [
    "print (\"Best baseline settings: \", best_baseline_settings)\n",
    "print (\"Best prefined settings: \", best_prefined_settings)\n",
    "print (\"Best baseline accuracy: \", best_baseline_accuracy)\n",
    "print (\"Best prefined accuracy: \", best_prefined_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Accuracy on test set: 0.5674157303370787\n",
      "Prefined Accuracy on test set: 0.5692883895131086\n",
      "Baseline Precision on test set: 0.5674157303370787\n",
      "Prefined Precision on test set: 0.5910224438902744\n",
      "Baseline Recall on test set: 1.0\n",
      "Prefined Recall on test set: 0.7821782178217822\n",
      "Baseline F1 on test set: 0.7240143369175627\n",
      "Prefined F1 on test set: 0.6732954545454546\n"
     ]
    }
   ],
   "source": [
    "# run on test set\n",
    "baseline_pred = best_baseline_svm.predict(X_test_baseline)\n",
    "prefined_pred = best_prefined_svm.predict(X_test_prefined)\n",
    "\n",
    "baseline_accuracy = accuracy_score(y_test, baseline_pred)\n",
    "prefined_accuracy = accuracy_score(y_test, prefined_pred)\n",
    "\n",
    "print(f\"Baseline Accuracy on test set: {baseline_accuracy}\")\n",
    "print(f\"Prefined Accuracy on test set: {prefined_accuracy}\")\n",
    "\n",
    "baseline_precision = precision_score(y_test, baseline_pred)\n",
    "prefined_precision = precision_score(y_test, prefined_pred)\n",
    "\n",
    "baseline_recall = recall_score(y_test, baseline_pred)\n",
    "prefined_recall = recall_score(y_test, prefined_pred)\n",
    "\n",
    "baseline_f1 = f1_score(y_test, baseline_pred)\n",
    "prefined_f1 = f1_score(y_test, prefined_pred)\n",
    "\n",
    "print(f\"Baseline Precision on test set: {baseline_precision}\")\n",
    "print(f\"Prefined Precision on test set: {prefined_precision}\")\n",
    "print(f\"Baseline Recall on test set: {baseline_recall}\")\n",
    "print(f\"Prefined Recall on test set: {prefined_recall}\")\n",
    "print(f\"Baseline F1 on test set: {baseline_f1}\")\n",
    "print(f\"Prefined F1 on test set: {prefined_f1}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Accuracy: 0.5928705440900562 when hidden_layer_sizes = (100, 50), activation = relu, solver = adam, learning_rate = constant, alpha = 0.0001\n",
      "Prefined Accuracy: 0.4652908067542214 when hidden_layer_sizes = (100, 50), activation = relu, solver = adam, learning_rate = constant, alpha = 0.0001\n",
      "Baseline Accuracy: 0.5928705440900562 when hidden_layer_sizes = (100, 50), activation = relu, solver = adam, learning_rate = constant, alpha = 0.001\n",
      "Prefined Accuracy: 0.5834896810506567 when hidden_layer_sizes = (100, 50), activation = relu, solver = adam, learning_rate = constant, alpha = 0.001\n",
      "Baseline Accuracy: 0.5928705440900562 when hidden_layer_sizes = (100, 50), activation = relu, solver = adam, learning_rate = constant, alpha = 0.01\n",
      "Prefined Accuracy: 0.4971857410881801 when hidden_layer_sizes = (100, 50), activation = relu, solver = adam, learning_rate = constant, alpha = 0.01\n",
      "Baseline Accuracy: 0.5928705440900562 when hidden_layer_sizes = (100, 50), activation = relu, solver = adam, learning_rate = adaptive, alpha = 0.0001\n",
      "Prefined Accuracy: 0.525328330206379 when hidden_layer_sizes = (100, 50), activation = relu, solver = adam, learning_rate = adaptive, alpha = 0.0001\n",
      "Baseline Accuracy: 0.5928705440900562 when hidden_layer_sizes = (100, 50), activation = relu, solver = adam, learning_rate = adaptive, alpha = 0.001\n",
      "Prefined Accuracy: 0.5928705440900562 when hidden_layer_sizes = (100, 50), activation = relu, solver = adam, learning_rate = adaptive, alpha = 0.001\n",
      "Baseline Accuracy: 0.5928705440900562 when hidden_layer_sizes = (100, 50), activation = relu, solver = adam, learning_rate = adaptive, alpha = 0.01\n",
      "Prefined Accuracy: 0.551594746716698 when hidden_layer_sizes = (100, 50), activation = relu, solver = adam, learning_rate = adaptive, alpha = 0.01\n",
      "Baseline Accuracy: 0.5928705440900562 when hidden_layer_sizes = (100, 50), activation = relu, solver = sgd, learning_rate = constant, alpha = 0.0001\n",
      "Prefined Accuracy: 0.525328330206379 when hidden_layer_sizes = (100, 50), activation = relu, solver = sgd, learning_rate = constant, alpha = 0.0001\n",
      "Baseline Accuracy: 0.5928705440900562 when hidden_layer_sizes = (100, 50), activation = relu, solver = sgd, learning_rate = constant, alpha = 0.001\n",
      "Prefined Accuracy: 0.5966228893058161 when hidden_layer_sizes = (100, 50), activation = relu, solver = sgd, learning_rate = constant, alpha = 0.001\n",
      "Baseline Accuracy: 0.5928705440900562 when hidden_layer_sizes = (100, 50), activation = relu, solver = sgd, learning_rate = constant, alpha = 0.01\n",
      "Prefined Accuracy: 0.5140712945590994 when hidden_layer_sizes = (100, 50), activation = relu, solver = sgd, learning_rate = constant, alpha = 0.01\n",
      "Baseline Accuracy: 0.5928705440900562 when hidden_layer_sizes = (100, 50), activation = relu, solver = sgd, learning_rate = adaptive, alpha = 0.0001\n",
      "Prefined Accuracy: 0.6135084427767354 when hidden_layer_sizes = (100, 50), activation = relu, solver = sgd, learning_rate = adaptive, alpha = 0.0001\n",
      "Baseline Accuracy: 0.5928705440900562 when hidden_layer_sizes = (100, 50), activation = relu, solver = sgd, learning_rate = adaptive, alpha = 0.001\n",
      "Prefined Accuracy: 0.6135084427767354 when hidden_layer_sizes = (100, 50), activation = relu, solver = sgd, learning_rate = adaptive, alpha = 0.001\n",
      "Baseline Accuracy: 0.5928705440900562 when hidden_layer_sizes = (100, 50), activation = relu, solver = sgd, learning_rate = adaptive, alpha = 0.01\n",
      "Prefined Accuracy: 0.5928705440900562 when hidden_layer_sizes = (100, 50), activation = relu, solver = sgd, learning_rate = adaptive, alpha = 0.01\n",
      "Baseline Accuracy: 0.5272045028142589 when hidden_layer_sizes = (100, 50), activation = tanh, solver = adam, learning_rate = constant, alpha = 0.0001\n",
      "Prefined Accuracy: 0.6153846153846154 when hidden_layer_sizes = (100, 50), activation = tanh, solver = adam, learning_rate = constant, alpha = 0.0001\n",
      "Baseline Accuracy: 0.5966228893058161 when hidden_layer_sizes = (100, 50), activation = tanh, solver = adam, learning_rate = constant, alpha = 0.001\n",
      "Prefined Accuracy: 0.5947467166979362 when hidden_layer_sizes = (100, 50), activation = tanh, solver = adam, learning_rate = constant, alpha = 0.001\n",
      "Baseline Accuracy: 0.5928705440900562 when hidden_layer_sizes = (100, 50), activation = tanh, solver = adam, learning_rate = constant, alpha = 0.01\n",
      "Prefined Accuracy: 0.6191369606003753 when hidden_layer_sizes = (100, 50), activation = tanh, solver = adam, learning_rate = constant, alpha = 0.01\n",
      "Baseline Accuracy: 0.5872420262664165 when hidden_layer_sizes = (100, 50), activation = tanh, solver = adam, learning_rate = adaptive, alpha = 0.0001\n",
      "Prefined Accuracy: 0.5422138836772983 when hidden_layer_sizes = (100, 50), activation = tanh, solver = adam, learning_rate = adaptive, alpha = 0.0001\n",
      "Baseline Accuracy: 0.5234521575984991 when hidden_layer_sizes = (100, 50), activation = tanh, solver = adam, learning_rate = adaptive, alpha = 0.001\n",
      "Prefined Accuracy: 0.6116322701688556 when hidden_layer_sizes = (100, 50), activation = tanh, solver = adam, learning_rate = adaptive, alpha = 0.001\n",
      "Baseline Accuracy: 0.5459662288930581 when hidden_layer_sizes = (100, 50), activation = tanh, solver = adam, learning_rate = adaptive, alpha = 0.01\n",
      "Prefined Accuracy: 0.6022514071294559 when hidden_layer_sizes = (100, 50), activation = tanh, solver = adam, learning_rate = adaptive, alpha = 0.01\n",
      "Baseline Accuracy: 0.5928705440900562 when hidden_layer_sizes = (100, 50), activation = tanh, solver = sgd, learning_rate = constant, alpha = 0.0001\n",
      "Prefined Accuracy: 0.5947467166979362 when hidden_layer_sizes = (100, 50), activation = tanh, solver = sgd, learning_rate = constant, alpha = 0.0001\n",
      "Baseline Accuracy: 0.5928705440900562 when hidden_layer_sizes = (100, 50), activation = tanh, solver = sgd, learning_rate = constant, alpha = 0.001\n",
      "Prefined Accuracy: 0.600375234521576 when hidden_layer_sizes = (100, 50), activation = tanh, solver = sgd, learning_rate = constant, alpha = 0.001\n",
      "Baseline Accuracy: 0.5928705440900562 when hidden_layer_sizes = (100, 50), activation = tanh, solver = sgd, learning_rate = constant, alpha = 0.01\n",
      "Prefined Accuracy: 0.5984990619136961 when hidden_layer_sizes = (100, 50), activation = tanh, solver = sgd, learning_rate = constant, alpha = 0.01\n",
      "Baseline Accuracy: 0.5928705440900562 when hidden_layer_sizes = (100, 50), activation = tanh, solver = sgd, learning_rate = adaptive, alpha = 0.0001\n",
      "Prefined Accuracy: 0.5984990619136961 when hidden_layer_sizes = (100, 50), activation = tanh, solver = sgd, learning_rate = adaptive, alpha = 0.0001\n",
      "Baseline Accuracy: 0.5928705440900562 when hidden_layer_sizes = (100, 50), activation = tanh, solver = sgd, learning_rate = adaptive, alpha = 0.001\n",
      "Prefined Accuracy: 0.6022514071294559 when hidden_layer_sizes = (100, 50), activation = tanh, solver = sgd, learning_rate = adaptive, alpha = 0.001\n",
      "Baseline Accuracy: 0.5928705440900562 when hidden_layer_sizes = (100, 50), activation = tanh, solver = sgd, learning_rate = adaptive, alpha = 0.01\n",
      "Prefined Accuracy: 0.6135084427767354 when hidden_layer_sizes = (100, 50), activation = tanh, solver = sgd, learning_rate = adaptive, alpha = 0.01\n",
      "Baseline Accuracy: 0.5928705440900562 when hidden_layer_sizes = (100, 50), activation = logistic, solver = adam, learning_rate = constant, alpha = 0.0001\n",
      "Prefined Accuracy: 0.5590994371482176 when hidden_layer_sizes = (100, 50), activation = logistic, solver = adam, learning_rate = constant, alpha = 0.0001\n",
      "Baseline Accuracy: 0.5928705440900562 when hidden_layer_sizes = (100, 50), activation = logistic, solver = adam, learning_rate = constant, alpha = 0.001\n",
      "Prefined Accuracy: 0.5928705440900562 when hidden_layer_sizes = (100, 50), activation = logistic, solver = adam, learning_rate = constant, alpha = 0.001\n",
      "Baseline Accuracy: 0.5928705440900562 when hidden_layer_sizes = (100, 50), activation = logistic, solver = adam, learning_rate = constant, alpha = 0.01\n",
      "Prefined Accuracy: 0.5797373358348968 when hidden_layer_sizes = (100, 50), activation = logistic, solver = adam, learning_rate = constant, alpha = 0.01\n",
      "Baseline Accuracy: 0.5928705440900562 when hidden_layer_sizes = (100, 50), activation = logistic, solver = adam, learning_rate = adaptive, alpha = 0.0001\n",
      "Prefined Accuracy: 0.626641651031895 when hidden_layer_sizes = (100, 50), activation = logistic, solver = adam, learning_rate = adaptive, alpha = 0.0001\n",
      "Baseline Accuracy: 0.5928705440900562 when hidden_layer_sizes = (100, 50), activation = logistic, solver = adam, learning_rate = adaptive, alpha = 0.001\n",
      "Prefined Accuracy: 0.5891181988742964 when hidden_layer_sizes = (100, 50), activation = logistic, solver = adam, learning_rate = adaptive, alpha = 0.001\n",
      "Baseline Accuracy: 0.5928705440900562 when hidden_layer_sizes = (100, 50), activation = logistic, solver = adam, learning_rate = adaptive, alpha = 0.01\n",
      "Prefined Accuracy: 0.626641651031895 when hidden_layer_sizes = (100, 50), activation = logistic, solver = adam, learning_rate = adaptive, alpha = 0.01\n",
      "Baseline Accuracy: 0.5928705440900562 when hidden_layer_sizes = (100, 50), activation = logistic, solver = sgd, learning_rate = constant, alpha = 0.0001\n",
      "Prefined Accuracy: 0.5928705440900562 when hidden_layer_sizes = (100, 50), activation = logistic, solver = sgd, learning_rate = constant, alpha = 0.0001\n",
      "Baseline Accuracy: 0.5928705440900562 when hidden_layer_sizes = (100, 50), activation = logistic, solver = sgd, learning_rate = constant, alpha = 0.001\n",
      "Prefined Accuracy: 0.5928705440900562 when hidden_layer_sizes = (100, 50), activation = logistic, solver = sgd, learning_rate = constant, alpha = 0.001\n",
      "Baseline Accuracy: 0.5928705440900562 when hidden_layer_sizes = (100, 50), activation = logistic, solver = sgd, learning_rate = constant, alpha = 0.01\n",
      "Prefined Accuracy: 0.5928705440900562 when hidden_layer_sizes = (100, 50), activation = logistic, solver = sgd, learning_rate = constant, alpha = 0.01\n",
      "Baseline Accuracy: 0.5928705440900562 when hidden_layer_sizes = (100, 50), activation = logistic, solver = sgd, learning_rate = adaptive, alpha = 0.0001\n",
      "Prefined Accuracy: 0.5928705440900562 when hidden_layer_sizes = (100, 50), activation = logistic, solver = sgd, learning_rate = adaptive, alpha = 0.0001\n",
      "Baseline Accuracy: 0.5928705440900562 when hidden_layer_sizes = (100, 50), activation = logistic, solver = sgd, learning_rate = adaptive, alpha = 0.001\n",
      "Prefined Accuracy: 0.5928705440900562 when hidden_layer_sizes = (100, 50), activation = logistic, solver = sgd, learning_rate = adaptive, alpha = 0.001\n",
      "Baseline Accuracy: 0.5928705440900562 when hidden_layer_sizes = (100, 50), activation = logistic, solver = sgd, learning_rate = adaptive, alpha = 0.01\n",
      "Prefined Accuracy: 0.5928705440900562 when hidden_layer_sizes = (100, 50), activation = logistic, solver = sgd, learning_rate = adaptive, alpha = 0.01\n",
      "Baseline Accuracy: 0.5928705440900562 when hidden_layer_sizes = (100, 100, 50), activation = relu, solver = adam, learning_rate = constant, alpha = 0.0001\n",
      "Prefined Accuracy: 0.5666041275797373 when hidden_layer_sizes = (100, 100, 50), activation = relu, solver = adam, learning_rate = constant, alpha = 0.0001\n",
      "Baseline Accuracy: 0.5928705440900562 when hidden_layer_sizes = (100, 100, 50), activation = relu, solver = adam, learning_rate = constant, alpha = 0.001\n",
      "Prefined Accuracy: 0.4727954971857411 when hidden_layer_sizes = (100, 100, 50), activation = relu, solver = adam, learning_rate = constant, alpha = 0.001\n",
      "Baseline Accuracy: 0.5928705440900562 when hidden_layer_sizes = (100, 100, 50), activation = relu, solver = adam, learning_rate = constant, alpha = 0.01\n",
      "Prefined Accuracy: 0.5928705440900562 when hidden_layer_sizes = (100, 100, 50), activation = relu, solver = adam, learning_rate = constant, alpha = 0.01\n",
      "Baseline Accuracy: 0.5928705440900562 when hidden_layer_sizes = (100, 100, 50), activation = relu, solver = adam, learning_rate = adaptive, alpha = 0.0001\n",
      "Prefined Accuracy: 0.6097560975609756 when hidden_layer_sizes = (100, 100, 50), activation = relu, solver = adam, learning_rate = adaptive, alpha = 0.0001\n",
      "Baseline Accuracy: 0.5928705440900562 when hidden_layer_sizes = (100, 100, 50), activation = relu, solver = adam, learning_rate = adaptive, alpha = 0.001\n",
      "Prefined Accuracy: 0.474671669793621 when hidden_layer_sizes = (100, 100, 50), activation = relu, solver = adam, learning_rate = adaptive, alpha = 0.001\n",
      "Baseline Accuracy: 0.5816135084427767 when hidden_layer_sizes = (100, 100, 50), activation = relu, solver = adam, learning_rate = adaptive, alpha = 0.01\n",
      "Prefined Accuracy: 0.6078799249530957 when hidden_layer_sizes = (100, 100, 50), activation = relu, solver = adam, learning_rate = adaptive, alpha = 0.01\n",
      "Baseline Accuracy: 0.5928705440900562 when hidden_layer_sizes = (100, 100, 50), activation = relu, solver = sgd, learning_rate = constant, alpha = 0.0001\n",
      "Prefined Accuracy: 0.6078799249530957 when hidden_layer_sizes = (100, 100, 50), activation = relu, solver = sgd, learning_rate = constant, alpha = 0.0001\n",
      "Baseline Accuracy: 0.5928705440900562 when hidden_layer_sizes = (100, 100, 50), activation = relu, solver = sgd, learning_rate = constant, alpha = 0.001\n",
      "Prefined Accuracy: 0.6097560975609756 when hidden_layer_sizes = (100, 100, 50), activation = relu, solver = sgd, learning_rate = constant, alpha = 0.001\n",
      "Baseline Accuracy: 0.5928705440900562 when hidden_layer_sizes = (100, 100, 50), activation = relu, solver = sgd, learning_rate = constant, alpha = 0.01\n",
      "Prefined Accuracy: 0.5966228893058161 when hidden_layer_sizes = (100, 100, 50), activation = relu, solver = sgd, learning_rate = constant, alpha = 0.01\n",
      "Baseline Accuracy: 0.5928705440900562 when hidden_layer_sizes = (100, 100, 50), activation = relu, solver = sgd, learning_rate = adaptive, alpha = 0.0001\n",
      "Prefined Accuracy: 0.6022514071294559 when hidden_layer_sizes = (100, 100, 50), activation = relu, solver = sgd, learning_rate = adaptive, alpha = 0.0001\n",
      "Baseline Accuracy: 0.5928705440900562 when hidden_layer_sizes = (100, 100, 50), activation = relu, solver = sgd, learning_rate = adaptive, alpha = 0.001\n",
      "Prefined Accuracy: 0.5909943714821764 when hidden_layer_sizes = (100, 100, 50), activation = relu, solver = sgd, learning_rate = adaptive, alpha = 0.001\n",
      "Baseline Accuracy: 0.5928705440900562 when hidden_layer_sizes = (100, 100, 50), activation = relu, solver = sgd, learning_rate = adaptive, alpha = 0.01\n",
      "Prefined Accuracy: 0.6116322701688556 when hidden_layer_sizes = (100, 100, 50), activation = relu, solver = sgd, learning_rate = adaptive, alpha = 0.01\n",
      "Baseline Accuracy: 0.5928705440900562 when hidden_layer_sizes = (100, 100, 50), activation = tanh, solver = adam, learning_rate = constant, alpha = 0.0001\n",
      "Prefined Accuracy: 0.5984990619136961 when hidden_layer_sizes = (100, 100, 50), activation = tanh, solver = adam, learning_rate = constant, alpha = 0.0001\n",
      "Baseline Accuracy: 0.5947467166979362 when hidden_layer_sizes = (100, 100, 50), activation = tanh, solver = adam, learning_rate = constant, alpha = 0.001\n",
      "Prefined Accuracy: 0.5984990619136961 when hidden_layer_sizes = (100, 100, 50), activation = tanh, solver = adam, learning_rate = constant, alpha = 0.001\n",
      "Baseline Accuracy: 0.5966228893058161 when hidden_layer_sizes = (100, 100, 50), activation = tanh, solver = adam, learning_rate = constant, alpha = 0.01\n",
      "Prefined Accuracy: 0.5478424015009381 when hidden_layer_sizes = (100, 100, 50), activation = tanh, solver = adam, learning_rate = constant, alpha = 0.01\n",
      "Baseline Accuracy: 0.5272045028142589 when hidden_layer_sizes = (100, 100, 50), activation = tanh, solver = adam, learning_rate = adaptive, alpha = 0.0001\n",
      "Prefined Accuracy: 0.5797373358348968 when hidden_layer_sizes = (100, 100, 50), activation = tanh, solver = adam, learning_rate = adaptive, alpha = 0.0001\n",
      "Baseline Accuracy: 0.5103189493433395 when hidden_layer_sizes = (100, 100, 50), activation = tanh, solver = adam, learning_rate = adaptive, alpha = 0.001\n",
      "Prefined Accuracy: 0.5928705440900562 when hidden_layer_sizes = (100, 100, 50), activation = tanh, solver = adam, learning_rate = adaptive, alpha = 0.001\n",
      "Baseline Accuracy: 0.5928705440900562 when hidden_layer_sizes = (100, 100, 50), activation = tanh, solver = adam, learning_rate = adaptive, alpha = 0.01\n",
      "Prefined Accuracy: 0.6153846153846154 when hidden_layer_sizes = (100, 100, 50), activation = tanh, solver = adam, learning_rate = adaptive, alpha = 0.01\n",
      "Baseline Accuracy: 0.5928705440900562 when hidden_layer_sizes = (100, 100, 50), activation = tanh, solver = sgd, learning_rate = constant, alpha = 0.0001\n",
      "Prefined Accuracy: 0.5722326454033771 when hidden_layer_sizes = (100, 100, 50), activation = tanh, solver = sgd, learning_rate = constant, alpha = 0.0001\n",
      "Baseline Accuracy: 0.5928705440900562 when hidden_layer_sizes = (100, 100, 50), activation = tanh, solver = sgd, learning_rate = constant, alpha = 0.001\n",
      "Prefined Accuracy: 0.6228893058161351 when hidden_layer_sizes = (100, 100, 50), activation = tanh, solver = sgd, learning_rate = constant, alpha = 0.001\n",
      "Baseline Accuracy: 0.5928705440900562 when hidden_layer_sizes = (100, 100, 50), activation = tanh, solver = sgd, learning_rate = constant, alpha = 0.01\n",
      "Prefined Accuracy: 0.5778611632270169 when hidden_layer_sizes = (100, 100, 50), activation = tanh, solver = sgd, learning_rate = constant, alpha = 0.01\n",
      "Baseline Accuracy: 0.5928705440900562 when hidden_layer_sizes = (100, 100, 50), activation = tanh, solver = sgd, learning_rate = adaptive, alpha = 0.0001\n",
      "Prefined Accuracy: 0.6116322701688556 when hidden_layer_sizes = (100, 100, 50), activation = tanh, solver = sgd, learning_rate = adaptive, alpha = 0.0001\n",
      "Baseline Accuracy: 0.5928705440900562 when hidden_layer_sizes = (100, 100, 50), activation = tanh, solver = sgd, learning_rate = adaptive, alpha = 0.001\n",
      "Prefined Accuracy: 0.5909943714821764 when hidden_layer_sizes = (100, 100, 50), activation = tanh, solver = sgd, learning_rate = adaptive, alpha = 0.001\n",
      "Baseline Accuracy: 0.5928705440900562 when hidden_layer_sizes = (100, 100, 50), activation = tanh, solver = sgd, learning_rate = adaptive, alpha = 0.01\n",
      "Prefined Accuracy: 0.5928705440900562 when hidden_layer_sizes = (100, 100, 50), activation = tanh, solver = sgd, learning_rate = adaptive, alpha = 0.01\n",
      "Baseline Accuracy: 0.5928705440900562 when hidden_layer_sizes = (100, 100, 50), activation = logistic, solver = adam, learning_rate = constant, alpha = 0.0001\n",
      "Prefined Accuracy: 0.6097560975609756 when hidden_layer_sizes = (100, 100, 50), activation = logistic, solver = adam, learning_rate = constant, alpha = 0.0001\n",
      "Baseline Accuracy: 0.5928705440900562 when hidden_layer_sizes = (100, 100, 50), activation = logistic, solver = adam, learning_rate = constant, alpha = 0.001\n",
      "Prefined Accuracy: 0.5928705440900562 when hidden_layer_sizes = (100, 100, 50), activation = logistic, solver = adam, learning_rate = constant, alpha = 0.001\n",
      "Baseline Accuracy: 0.5928705440900562 when hidden_layer_sizes = (100, 100, 50), activation = logistic, solver = adam, learning_rate = constant, alpha = 0.01\n",
      "Prefined Accuracy: 0.5928705440900562 when hidden_layer_sizes = (100, 100, 50), activation = logistic, solver = adam, learning_rate = constant, alpha = 0.01\n",
      "Baseline Accuracy: 0.5928705440900562 when hidden_layer_sizes = (100, 100, 50), activation = logistic, solver = adam, learning_rate = adaptive, alpha = 0.0001\n",
      "Prefined Accuracy: 0.5928705440900562 when hidden_layer_sizes = (100, 100, 50), activation = logistic, solver = adam, learning_rate = adaptive, alpha = 0.0001\n",
      "Baseline Accuracy: 0.5928705440900562 when hidden_layer_sizes = (100, 100, 50), activation = logistic, solver = adam, learning_rate = adaptive, alpha = 0.001\n",
      "Prefined Accuracy: 0.5928705440900562 when hidden_layer_sizes = (100, 100, 50), activation = logistic, solver = adam, learning_rate = adaptive, alpha = 0.001\n",
      "Baseline Accuracy: 0.5928705440900562 when hidden_layer_sizes = (100, 100, 50), activation = logistic, solver = adam, learning_rate = adaptive, alpha = 0.01\n",
      "Prefined Accuracy: 0.5928705440900562 when hidden_layer_sizes = (100, 100, 50), activation = logistic, solver = adam, learning_rate = adaptive, alpha = 0.01\n",
      "Baseline Accuracy: 0.5928705440900562 when hidden_layer_sizes = (100, 100, 50), activation = logistic, solver = sgd, learning_rate = constant, alpha = 0.0001\n",
      "Prefined Accuracy: 0.5928705440900562 when hidden_layer_sizes = (100, 100, 50), activation = logistic, solver = sgd, learning_rate = constant, alpha = 0.0001\n",
      "Baseline Accuracy: 0.5928705440900562 when hidden_layer_sizes = (100, 100, 50), activation = logistic, solver = sgd, learning_rate = constant, alpha = 0.001\n",
      "Prefined Accuracy: 0.5928705440900562 when hidden_layer_sizes = (100, 100, 50), activation = logistic, solver = sgd, learning_rate = constant, alpha = 0.001\n",
      "Baseline Accuracy: 0.5928705440900562 when hidden_layer_sizes = (100, 100, 50), activation = logistic, solver = sgd, learning_rate = constant, alpha = 0.01\n",
      "Prefined Accuracy: 0.5928705440900562 when hidden_layer_sizes = (100, 100, 50), activation = logistic, solver = sgd, learning_rate = constant, alpha = 0.01\n",
      "Baseline Accuracy: 0.5928705440900562 when hidden_layer_sizes = (100, 100, 50), activation = logistic, solver = sgd, learning_rate = adaptive, alpha = 0.0001\n",
      "Prefined Accuracy: 0.5928705440900562 when hidden_layer_sizes = (100, 100, 50), activation = logistic, solver = sgd, learning_rate = adaptive, alpha = 0.0001\n",
      "Baseline Accuracy: 0.5928705440900562 when hidden_layer_sizes = (100, 100, 50), activation = logistic, solver = sgd, learning_rate = adaptive, alpha = 0.001\n",
      "Prefined Accuracy: 0.5928705440900562 when hidden_layer_sizes = (100, 100, 50), activation = logistic, solver = sgd, learning_rate = adaptive, alpha = 0.001\n",
      "Baseline Accuracy: 0.5928705440900562 when hidden_layer_sizes = (100, 100, 50), activation = logistic, solver = sgd, learning_rate = adaptive, alpha = 0.01\n",
      "Prefined Accuracy: 0.5928705440900562 when hidden_layer_sizes = (100, 100, 50), activation = logistic, solver = sgd, learning_rate = adaptive, alpha = 0.01\n",
      "Baseline Accuracy: 0.5928705440900562 when hidden_layer_sizes = (100, 100, 100, 50), activation = relu, solver = adam, learning_rate = constant, alpha = 0.0001\n",
      "Prefined Accuracy: 0.6022514071294559 when hidden_layer_sizes = (100, 100, 100, 50), activation = relu, solver = adam, learning_rate = constant, alpha = 0.0001\n",
      "Baseline Accuracy: 0.5928705440900562 when hidden_layer_sizes = (100, 100, 100, 50), activation = relu, solver = adam, learning_rate = constant, alpha = 0.001\n",
      "Prefined Accuracy: 0.6135084427767354 when hidden_layer_sizes = (100, 100, 100, 50), activation = relu, solver = adam, learning_rate = constant, alpha = 0.001\n",
      "Baseline Accuracy: 0.5928705440900562 when hidden_layer_sizes = (100, 100, 100, 50), activation = relu, solver = adam, learning_rate = constant, alpha = 0.01\n",
      "Prefined Accuracy: 0.6135084427767354 when hidden_layer_sizes = (100, 100, 100, 50), activation = relu, solver = adam, learning_rate = constant, alpha = 0.01\n",
      "Baseline Accuracy: 0.5928705440900562 when hidden_layer_sizes = (100, 100, 100, 50), activation = relu, solver = adam, learning_rate = adaptive, alpha = 0.0001\n",
      "Prefined Accuracy: 0.6060037523452158 when hidden_layer_sizes = (100, 100, 100, 50), activation = relu, solver = adam, learning_rate = adaptive, alpha = 0.0001\n",
      "Baseline Accuracy: 0.5928705440900562 when hidden_layer_sizes = (100, 100, 100, 50), activation = relu, solver = adam, learning_rate = adaptive, alpha = 0.001\n",
      "Prefined Accuracy: 0.5234521575984991 when hidden_layer_sizes = (100, 100, 100, 50), activation = relu, solver = adam, learning_rate = adaptive, alpha = 0.001\n",
      "Baseline Accuracy: 0.5928705440900562 when hidden_layer_sizes = (100, 100, 100, 50), activation = relu, solver = adam, learning_rate = adaptive, alpha = 0.01\n",
      "Prefined Accuracy: 0.5928705440900562 when hidden_layer_sizes = (100, 100, 100, 50), activation = relu, solver = adam, learning_rate = adaptive, alpha = 0.01\n",
      "Baseline Accuracy: 0.5928705440900562 when hidden_layer_sizes = (100, 100, 100, 50), activation = relu, solver = sgd, learning_rate = constant, alpha = 0.0001\n",
      "Prefined Accuracy: 0.5928705440900562 when hidden_layer_sizes = (100, 100, 100, 50), activation = relu, solver = sgd, learning_rate = constant, alpha = 0.0001\n",
      "Baseline Accuracy: 0.5928705440900562 when hidden_layer_sizes = (100, 100, 100, 50), activation = relu, solver = sgd, learning_rate = constant, alpha = 0.001\n",
      "Prefined Accuracy: 0.5928705440900562 when hidden_layer_sizes = (100, 100, 100, 50), activation = relu, solver = sgd, learning_rate = constant, alpha = 0.001\n",
      "Baseline Accuracy: 0.5928705440900562 when hidden_layer_sizes = (100, 100, 100, 50), activation = relu, solver = sgd, learning_rate = constant, alpha = 0.01\n",
      "Prefined Accuracy: 0.5440900562851783 when hidden_layer_sizes = (100, 100, 100, 50), activation = relu, solver = sgd, learning_rate = constant, alpha = 0.01\n",
      "Baseline Accuracy: 0.5928705440900562 when hidden_layer_sizes = (100, 100, 100, 50), activation = relu, solver = sgd, learning_rate = adaptive, alpha = 0.0001\n",
      "Prefined Accuracy: 0.6097560975609756 when hidden_layer_sizes = (100, 100, 100, 50), activation = relu, solver = sgd, learning_rate = adaptive, alpha = 0.0001\n",
      "Baseline Accuracy: 0.5928705440900562 when hidden_layer_sizes = (100, 100, 100, 50), activation = relu, solver = sgd, learning_rate = adaptive, alpha = 0.001\n",
      "Prefined Accuracy: 0.5891181988742964 when hidden_layer_sizes = (100, 100, 100, 50), activation = relu, solver = sgd, learning_rate = adaptive, alpha = 0.001\n",
      "Baseline Accuracy: 0.5928705440900562 when hidden_layer_sizes = (100, 100, 100, 50), activation = relu, solver = sgd, learning_rate = adaptive, alpha = 0.01\n",
      "Prefined Accuracy: 0.5797373358348968 when hidden_layer_sizes = (100, 100, 100, 50), activation = relu, solver = sgd, learning_rate = adaptive, alpha = 0.01\n",
      "Baseline Accuracy: 0.5928705440900562 when hidden_layer_sizes = (100, 100, 100, 50), activation = tanh, solver = adam, learning_rate = constant, alpha = 0.0001\n",
      "Prefined Accuracy: 0.47654784240150094 when hidden_layer_sizes = (100, 100, 100, 50), activation = tanh, solver = adam, learning_rate = constant, alpha = 0.0001\n",
      "Baseline Accuracy: 0.5891181988742964 when hidden_layer_sizes = (100, 100, 100, 50), activation = tanh, solver = adam, learning_rate = constant, alpha = 0.001\n",
      "Prefined Accuracy: 0.5947467166979362 when hidden_layer_sizes = (100, 100, 100, 50), activation = tanh, solver = adam, learning_rate = constant, alpha = 0.001\n",
      "Baseline Accuracy: 0.5272045028142589 when hidden_layer_sizes = (100, 100, 100, 50), activation = tanh, solver = adam, learning_rate = constant, alpha = 0.01\n",
      "Prefined Accuracy: 0.6078799249530957 when hidden_layer_sizes = (100, 100, 100, 50), activation = tanh, solver = adam, learning_rate = constant, alpha = 0.01\n",
      "Baseline Accuracy: 0.551594746716698 when hidden_layer_sizes = (100, 100, 100, 50), activation = tanh, solver = adam, learning_rate = adaptive, alpha = 0.0001\n",
      "Prefined Accuracy: 0.6172607879924953 when hidden_layer_sizes = (100, 100, 100, 50), activation = tanh, solver = adam, learning_rate = adaptive, alpha = 0.0001\n",
      "Baseline Accuracy: 0.5928705440900562 when hidden_layer_sizes = (100, 100, 100, 50), activation = tanh, solver = adam, learning_rate = adaptive, alpha = 0.001\n",
      "Prefined Accuracy: 0.574108818011257 when hidden_layer_sizes = (100, 100, 100, 50), activation = tanh, solver = adam, learning_rate = adaptive, alpha = 0.001\n",
      "Baseline Accuracy: 0.5928705440900562 when hidden_layer_sizes = (100, 100, 100, 50), activation = tanh, solver = adam, learning_rate = adaptive, alpha = 0.01\n",
      "Prefined Accuracy: 0.624765478424015 when hidden_layer_sizes = (100, 100, 100, 50), activation = tanh, solver = adam, learning_rate = adaptive, alpha = 0.01\n",
      "Baseline Accuracy: 0.5928705440900562 when hidden_layer_sizes = (100, 100, 100, 50), activation = tanh, solver = sgd, learning_rate = constant, alpha = 0.0001\n",
      "Prefined Accuracy: 0.624765478424015 when hidden_layer_sizes = (100, 100, 100, 50), activation = tanh, solver = sgd, learning_rate = constant, alpha = 0.0001\n",
      "Baseline Accuracy: 0.5928705440900562 when hidden_layer_sizes = (100, 100, 100, 50), activation = tanh, solver = sgd, learning_rate = constant, alpha = 0.001\n",
      "Prefined Accuracy: 0.6116322701688556 when hidden_layer_sizes = (100, 100, 100, 50), activation = tanh, solver = sgd, learning_rate = constant, alpha = 0.001\n",
      "Baseline Accuracy: 0.5928705440900562 when hidden_layer_sizes = (100, 100, 100, 50), activation = tanh, solver = sgd, learning_rate = constant, alpha = 0.01\n",
      "Prefined Accuracy: 0.5928705440900562 when hidden_layer_sizes = (100, 100, 100, 50), activation = tanh, solver = sgd, learning_rate = constant, alpha = 0.01\n",
      "Baseline Accuracy: 0.5928705440900562 when hidden_layer_sizes = (100, 100, 100, 50), activation = tanh, solver = sgd, learning_rate = adaptive, alpha = 0.0001\n",
      "Prefined Accuracy: 0.6022514071294559 when hidden_layer_sizes = (100, 100, 100, 50), activation = tanh, solver = sgd, learning_rate = adaptive, alpha = 0.0001\n",
      "Baseline Accuracy: 0.5928705440900562 when hidden_layer_sizes = (100, 100, 100, 50), activation = tanh, solver = sgd, learning_rate = adaptive, alpha = 0.001\n",
      "Prefined Accuracy: 0.6097560975609756 when hidden_layer_sizes = (100, 100, 100, 50), activation = tanh, solver = sgd, learning_rate = adaptive, alpha = 0.001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Accuracy: 0.5928705440900562 when hidden_layer_sizes = (100, 100, 100, 50), activation = tanh, solver = sgd, learning_rate = adaptive, alpha = 0.01\n",
      "Prefined Accuracy: 0.6097560975609756 when hidden_layer_sizes = (100, 100, 100, 50), activation = tanh, solver = sgd, learning_rate = adaptive, alpha = 0.01\n",
      "Baseline Accuracy: 0.5928705440900562 when hidden_layer_sizes = (100, 100, 100, 50), activation = logistic, solver = adam, learning_rate = constant, alpha = 0.0001\n",
      "Prefined Accuracy: 0.5928705440900562 when hidden_layer_sizes = (100, 100, 100, 50), activation = logistic, solver = adam, learning_rate = constant, alpha = 0.0001\n",
      "Baseline Accuracy: 0.5928705440900562 when hidden_layer_sizes = (100, 100, 100, 50), activation = logistic, solver = adam, learning_rate = constant, alpha = 0.001\n",
      "Prefined Accuracy: 0.5928705440900562 when hidden_layer_sizes = (100, 100, 100, 50), activation = logistic, solver = adam, learning_rate = constant, alpha = 0.001\n",
      "Baseline Accuracy: 0.5928705440900562 when hidden_layer_sizes = (100, 100, 100, 50), activation = logistic, solver = adam, learning_rate = constant, alpha = 0.01\n",
      "Prefined Accuracy: 0.5928705440900562 when hidden_layer_sizes = (100, 100, 100, 50), activation = logistic, solver = adam, learning_rate = constant, alpha = 0.01\n",
      "Baseline Accuracy: 0.5928705440900562 when hidden_layer_sizes = (100, 100, 100, 50), activation = logistic, solver = adam, learning_rate = adaptive, alpha = 0.0001\n",
      "Prefined Accuracy: 0.5928705440900562 when hidden_layer_sizes = (100, 100, 100, 50), activation = logistic, solver = adam, learning_rate = adaptive, alpha = 0.0001\n",
      "Baseline Accuracy: 0.5928705440900562 when hidden_layer_sizes = (100, 100, 100, 50), activation = logistic, solver = adam, learning_rate = adaptive, alpha = 0.001\n",
      "Prefined Accuracy: 0.5928705440900562 when hidden_layer_sizes = (100, 100, 100, 50), activation = logistic, solver = adam, learning_rate = adaptive, alpha = 0.001\n",
      "Baseline Accuracy: 0.5928705440900562 when hidden_layer_sizes = (100, 100, 100, 50), activation = logistic, solver = adam, learning_rate = adaptive, alpha = 0.01\n",
      "Prefined Accuracy: 0.5928705440900562 when hidden_layer_sizes = (100, 100, 100, 50), activation = logistic, solver = adam, learning_rate = adaptive, alpha = 0.01\n",
      "Baseline Accuracy: 0.5928705440900562 when hidden_layer_sizes = (100, 100, 100, 50), activation = logistic, solver = sgd, learning_rate = constant, alpha = 0.0001\n",
      "Prefined Accuracy: 0.5928705440900562 when hidden_layer_sizes = (100, 100, 100, 50), activation = logistic, solver = sgd, learning_rate = constant, alpha = 0.0001\n",
      "Baseline Accuracy: 0.5928705440900562 when hidden_layer_sizes = (100, 100, 100, 50), activation = logistic, solver = sgd, learning_rate = constant, alpha = 0.001\n",
      "Prefined Accuracy: 0.5928705440900562 when hidden_layer_sizes = (100, 100, 100, 50), activation = logistic, solver = sgd, learning_rate = constant, alpha = 0.001\n",
      "Baseline Accuracy: 0.5928705440900562 when hidden_layer_sizes = (100, 100, 100, 50), activation = logistic, solver = sgd, learning_rate = constant, alpha = 0.01\n",
      "Prefined Accuracy: 0.5928705440900562 when hidden_layer_sizes = (100, 100, 100, 50), activation = logistic, solver = sgd, learning_rate = constant, alpha = 0.01\n",
      "Baseline Accuracy: 0.5928705440900562 when hidden_layer_sizes = (100, 100, 100, 50), activation = logistic, solver = sgd, learning_rate = adaptive, alpha = 0.0001\n",
      "Prefined Accuracy: 0.5928705440900562 when hidden_layer_sizes = (100, 100, 100, 50), activation = logistic, solver = sgd, learning_rate = adaptive, alpha = 0.0001\n",
      "Baseline Accuracy: 0.5928705440900562 when hidden_layer_sizes = (100, 100, 100, 50), activation = logistic, solver = sgd, learning_rate = adaptive, alpha = 0.001\n",
      "Prefined Accuracy: 0.5928705440900562 when hidden_layer_sizes = (100, 100, 100, 50), activation = logistic, solver = sgd, learning_rate = adaptive, alpha = 0.001\n",
      "Baseline Accuracy: 0.5928705440900562 when hidden_layer_sizes = (100, 100, 100, 50), activation = logistic, solver = sgd, learning_rate = adaptive, alpha = 0.01\n",
      "Prefined Accuracy: 0.5928705440900562 when hidden_layer_sizes = (100, 100, 100, 50), activation = logistic, solver = sgd, learning_rate = adaptive, alpha = 0.01\n"
     ]
    }
   ],
   "source": [
    "# train neural network model\n",
    "hidden_layer_sizes = [(100, 50), (100, 100, 50), (100, 100, 100, 50)]\n",
    "activations = ['relu', 'tanh', 'logistic']\n",
    "solvers = ['adam', 'sgd']\n",
    "learning_rates = ['constant', 'adaptive']\n",
    "alphas = [0.0001, 0.001, 0.01]\n",
    "\n",
    "best_baseline_accuracy = np.zeros(1)\n",
    "best_prefined_accuracy = np.zeros(1)\n",
    "\n",
    "best_baseline_nn = None\n",
    "best_prefined_nn = None\n",
    "\n",
    "best_baseline_settings = {\n",
    "    \"hidden_layer_sizes\": None,\n",
    "    \"activation\": None,\n",
    "    \"solver\": None,\n",
    "    \"learning_rate\": None,\n",
    "    \"alpha\": None\n",
    "}\n",
    "best_prefined_settings = {\n",
    "    \"hidden_layer_sizes\": None,\n",
    "    \"activation\": None,\n",
    "    \"solver\": None,\n",
    "    \"learning_rate\": None,\n",
    "    \"alpha\": None\n",
    "}\n",
    "\n",
    "for h in hidden_layer_sizes:\n",
    "    for a in activations:\n",
    "        for s in solvers:\n",
    "            for l in learning_rates:\n",
    "                for alpha in alphas:\n",
    "                    nn_baseline = MLPClassifier(hidden_layer_sizes=h, activation=a, solver=s, learning_rate=l, alpha=alpha)\n",
    "                    nn_prefined = MLPClassifier(hidden_layer_sizes=h, activation=a, solver=s, learning_rate=l, alpha=alpha)\n",
    "                    \n",
    "                    # Train network\n",
    "                    nn_baseline.fit(X_train_baseline, y_train)\n",
    "                    nn_prefined.fit(X_train_prefined, y_train)\n",
    "                    \n",
    "                    # Test network\n",
    "                    # train accuracy\n",
    "                    train_accuracy_baseline = nn_baseline.score(X_train_baseline, y_train)\n",
    "                    train_accuracy_prefined = nn_prefined.score(X_train_prefined, y_train)\n",
    "                    \n",
    "                    # inference\n",
    "                    baseline_pred = nn_baseline.predict(X_dev_baseline)\n",
    "                    prefined_pred = nn_prefined.predict(X_dev_prefined)\n",
    "                    \n",
    "                    # Compute accuracy\n",
    "                    baseline_accuracy = accuracy_score(y_dev, baseline_pred)\n",
    "                    print(f\"Baseline Accuracy: {baseline_accuracy} when hidden_layer_sizes = {h}, activation = {a}, solver = {s}, learning_rate = {l}, alpha = {alpha}\")\n",
    "                    prefined_accuracy = accuracy_score(y_dev, prefined_pred)\n",
    "                    print(f\"Prefined Accuracy: {prefined_accuracy} when hidden_layer_sizes = {h}, activation = {a}, solver = {s}, learning_rate = {l}, alpha = {alpha}\")\n",
    "                    \n",
    "                    # Compute precision\n",
    "                    baseline_precision = precision_score(y_dev, baseline_pred)\n",
    "                    prefined_precision = precision_score(y_dev, prefined_pred)\n",
    "                    \n",
    "                    # Compute recall\n",
    "                    baseline_recall = recall_score(y_dev, baseline_pred)\n",
    "                    prefined_recall = recall_score(y_dev, prefined_pred)\n",
    "                    \n",
    "                    # Compute f1 score\n",
    "                    baseline_f1 = f1_score(y_dev, baseline_pred)\n",
    "                    prefined_f1 = f1_score(y_dev, prefined_pred)\n",
    "                    \n",
    "                    # Is it the best setting\n",
    "                    if baseline_accuracy >= best_baseline_accuracy:\n",
    "                        best_baseline_accuracy = baseline_accuracy\n",
    "                        best_baseline_settings = {\n",
    "                            \"hidden_layer_sizes\": h,\n",
    "                            \"activation\": a,\n",
    "                            \"solver\": s,\n",
    "                            \"learning_rate\": l,\n",
    "                            \"alpha\": alpha\n",
    "                        }\n",
    "                        best_baseline_nn = nn_baseline\n",
    "                    if prefined_accuracy >= best_prefined_accuracy:\n",
    "                        best_prefined_accuracy = prefined_accuracy\n",
    "                        best_prefined_settings = {\n",
    "                            \"hidden_layer_sizes\": h,\n",
    "                            \"activation\": a,\n",
    "                            \"solver\": s,\n",
    "                            \"learning_rate\": l,\n",
    "                            \"alpha\": alpha\n",
    "                        }\n",
    "                        best_prefined_nn = nn_prefined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best baseline settings:  {'hidden_layer_sizes': (100, 100, 50), 'activation': 'tanh', 'solver': 'adam', 'learning_rate': 'constant', 'alpha': 0.01}\n",
      "Best prefined settings:  {'hidden_layer_sizes': (100, 50), 'activation': 'logistic', 'solver': 'adam', 'learning_rate': 'adaptive', 'alpha': 0.01}\n",
      "Best baseline accuracy:  0.5966228893058161\n",
      "Best prefined accuracy:  0.626641651031895\n"
     ]
    }
   ],
   "source": [
    "print (\"Best baseline settings: \", best_baseline_settings)\n",
    "print (\"Best prefined settings: \", best_prefined_settings)\n",
    "\n",
    "print (\"Best baseline accuracy: \", best_baseline_accuracy)\n",
    "print (\"Best prefined accuracy: \", best_prefined_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Accuracy on test set: 0.6142322097378277\n",
      "Prefined Accuracy on test set: 0.5936329588014981\n",
      "Baseline Precision on test set: 0.6227848101265823\n",
      "Prefined Precision on test set: 0.5899581589958159\n",
      "Baseline Recall on test set: 0.8118811881188119\n",
      "Prefined Recall on test set: 0.9306930693069307\n",
      "Baseline F1 on test set: 0.7048710601719198\n",
      "Prefined F1 on test set: 0.7221510883482715\n"
     ]
    }
   ],
   "source": [
    "# run on test set\n",
    "baseline_pred = best_baseline_nn.predict(X_test_baseline)\n",
    "prefined_pred = best_prefined_nn.predict(X_test_prefined)\n",
    "\n",
    "baseline_accuracy = accuracy_score(y_test, baseline_pred)\n",
    "prefined_accuracy = accuracy_score(y_test, prefined_pred)\n",
    "\n",
    "print(f\"Baseline Accuracy on test set: {baseline_accuracy}\")\n",
    "print(f\"Prefined Accuracy on test set: {prefined_accuracy}\")\n",
    "\n",
    "baseline_precision = precision_score(y_test, baseline_pred)\n",
    "prefined_precision = precision_score(y_test, prefined_pred)\n",
    "\n",
    "baseline_recall = recall_score(y_test, baseline_pred)\n",
    "prefined_recall = recall_score(y_test, prefined_pred)\n",
    "\n",
    "baseline_f1 = f1_score(y_test, baseline_pred)\n",
    "prefined_f1 = f1_score(y_test, prefined_pred)\n",
    "\n",
    "print(f\"Baseline Precision on test set: {baseline_precision}\")\n",
    "print(f\"Prefined Precision on test set: {prefined_precision}\")\n",
    "print(f\"Baseline Recall on test set: {baseline_recall}\")\n",
    "print(f\"Prefined Recall on test set: {prefined_recall}\")\n",
    "print(f\"Baseline F1 on test set: {baseline_f1}\")\n",
    "print(f\"Prefined F1 on test set: {prefined_f1}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Accuracy: 0.5478424015009381 when criterion = gini, splitter = best\n",
      "Prefined Accuracy: 0.5440900562851783 when criterion = gini, splitter = best\n",
      "Baseline Accuracy: 0.5478424015009381 when criterion = gini, splitter = random\n",
      "Prefined Accuracy: 0.5478424015009381 when criterion = gini, splitter = random\n",
      "Baseline Accuracy: 0.5478424015009381 when criterion = entropy, splitter = best\n",
      "Prefined Accuracy: 0.5440900562851783 when criterion = entropy, splitter = best\n",
      "Baseline Accuracy: 0.5478424015009381 when criterion = entropy, splitter = random\n",
      "Prefined Accuracy: 0.5478424015009381 when criterion = entropy, splitter = random\n"
     ]
    }
   ],
   "source": [
    "# train decision tree model\n",
    "criteria = ['gini', 'entropy']\n",
    "splitters = ['best', 'random']\n",
    "\n",
    "best_baseline_accuracy = np.zeros(1)\n",
    "best_prefined_accuracy = np.zeros(1)\n",
    "\n",
    "best_baseline_tree = None\n",
    "best_prefined_tree = None\n",
    "\n",
    "best_baseline_settings = {\n",
    "    \"criterion\": None,\n",
    "    \"splitter\": None\n",
    "}\n",
    "best_prefined_settings = {  \n",
    "    \"criterion\": None,\n",
    "    \"splitter\": None\n",
    "}\n",
    "\n",
    "for c in criteria:\n",
    "    for s in splitters:\n",
    "        tree_baseline = DecisionTreeClassifier(criterion=c, splitter=s)\n",
    "        tree_prefined = DecisionTreeClassifier(criterion=c, splitter=s)\n",
    "        \n",
    "        # Train network\n",
    "        tree_baseline.fit(X_train_baseline, y_train)\n",
    "        tree_prefined.fit(X_train_prefined, y_train)\n",
    "        \n",
    "        # Test network\n",
    "        # train accuracy\n",
    "        train_accuracy_baseline = tree_baseline.score(X_train_baseline, y_train)\n",
    "        train_accuracy_prefined = tree_prefined.score(X_train_prefined, y_train)\n",
    "        \n",
    "        # inference\n",
    "        baseline_pred = tree_baseline.predict(X_dev_baseline)\n",
    "        prefined_pred = tree_prefined.predict(X_dev_prefined)\n",
    "        \n",
    "        # Compute accuracy\n",
    "        baseline_accuracy = accuracy_score(y_dev, baseline_pred)\n",
    "        print(f\"Baseline Accuracy: {baseline_accuracy} when criterion = {c}, splitter = {s}\")\n",
    "        prefined_accuracy = accuracy_score(y_dev, prefined_pred)\n",
    "        print(f\"Prefined Accuracy: {prefined_accuracy} when criterion = {c}, splitter = {s}\")\n",
    "        \n",
    "        # Compute precision\n",
    "        baseline_precision = precision_score(y_dev, baseline_pred)\n",
    "        prefined_precision = precision_score(y_dev, prefined_pred)\n",
    "        \n",
    "        # Compute recall\n",
    "        baseline_recall = recall_score(y_dev, baseline_pred)\n",
    "        prefined_recall = recall_score(y_dev, prefined_pred)\n",
    "        \n",
    "        # Compute f1 score\n",
    "        baseline_f1 = f1_score(y_dev, baseline_pred)\n",
    "        prefined_f1 = f1_score(y_dev, prefined_pred)\n",
    "        \n",
    "        # Is it the best setting\n",
    "        if baseline_accuracy >= best_baseline_accuracy:\n",
    "            best_baseline_accuracy = baseline_accuracy\n",
    "            best_baseline_settings = {\n",
    "                \"criterion\": c,\n",
    "                \"splitter\": s\n",
    "            }\n",
    "            best_baseline_tree = tree_baseline\n",
    "        if prefined_accuracy >= best_prefined_accuracy:\n",
    "            best_prefined_accuracy = prefined_accuracy\n",
    "            best_prefined_settings = {\n",
    "                \"criterion\": c,\n",
    "                \"splitter\": s\n",
    "            }\n",
    "            best_prefined_tree = tree_prefined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best baseline settings:  {'criterion': 'entropy', 'splitter': 'random'}\n",
      "Best prefined settings:  {'criterion': 'entropy', 'splitter': 'random'}\n",
      "Best baseline accuracy:  0.5478424015009381\n",
      "Best prefined accuracy:  0.5478424015009381\n"
     ]
    }
   ],
   "source": [
    "print(\"Best baseline settings: \", best_baseline_settings)\n",
    "print(\"Best prefined settings: \", best_prefined_settings)\n",
    "\n",
    "print(\"Best baseline accuracy: \", best_baseline_accuracy)\n",
    "print(\"Best prefined accuracy: \", best_prefined_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Accuracy on test set: 0.5393258426966292\n",
      "Prefined Accuracy on test set: 0.5393258426966292\n",
      "Baseline Precision on test set: 0.6014234875444839\n",
      "Prefined Precision on test set: 0.6014234875444839\n",
      "Baseline Recall on test set: 0.5577557755775577\n",
      "Prefined Recall on test set: 0.5577557755775577\n",
      "Baseline F1 on test set: 0.5787671232876712\n",
      "Prefined F1 on test set: 0.5787671232876712\n"
     ]
    }
   ],
   "source": [
    "# run on test set\n",
    "baseline_pred = best_baseline_tree.predict(X_test_baseline)\n",
    "prefined_pred = best_prefined_tree.predict(X_test_prefined)\n",
    "\n",
    "baseline_accuracy = accuracy_score(y_test, baseline_pred)\n",
    "prefined_accuracy = accuracy_score(y_test, prefined_pred)\n",
    "\n",
    "print(f\"Baseline Accuracy on test set: {baseline_accuracy}\")\n",
    "print(f\"Prefined Accuracy on test set: {prefined_accuracy}\")\n",
    "\n",
    "baseline_precision = precision_score(y_test, baseline_pred)\n",
    "prefined_precision = precision_score(y_test, prefined_pred)\n",
    "\n",
    "baseline_recall = recall_score(y_test, baseline_pred)\n",
    "prefined_recall = recall_score(y_test, prefined_pred)\n",
    "\n",
    "baseline_f1 = f1_score(y_test, baseline_pred)\n",
    "prefined_f1 = f1_score(y_test, prefined_pred)\n",
    "\n",
    "print(f\"Baseline Precision on test set: {baseline_precision}\")\n",
    "print(f\"Prefined Precision on test set: {prefined_precision}\")\n",
    "print(f\"Baseline Recall on test set: {baseline_recall}\")\n",
    "print(f\"Prefined Recall on test set: {prefined_recall}\")\n",
    "print(f\"Baseline F1 on test set: {baseline_f1}\")\n",
    "print(f\"Prefined F1 on test set: {prefined_f1}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
